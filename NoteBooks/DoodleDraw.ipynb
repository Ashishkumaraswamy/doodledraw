{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kxoUhbERlQA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNI6FyyWtwGs",
        "outputId": "021cd508-18a0-4320-c38f-256e136f6abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-03-10 13:36:11--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt’\n",
            "\n",
            "\rmini_classes.txt      0%[                    ]       0  --.-KB/s               \rmini_classes.txt    100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-10 13:36:11 (34.2 MB/s) - ‘mini_classes.txt’ saved [760/760]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vv7F_dE0uECS"
      },
      "outputs": [],
      "source": [
        "f = open(\"mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1oR4oZnzuLF3"
      },
      "outputs": [],
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wfn3YPW2uM94"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GNkgyhtNuPZQ"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "    base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "    for c in classes:        \n",
        "        cls_url = c.replace('_', '%20')\n",
        "        path = base+cls_url+'.npy'\n",
        "        print(path)\n",
        "        urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dwq0KFAuRWV",
        "outputId": "c74fa03f-c81a-4ba3-9f0c-4f36f36768ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ]
        }
      ],
      "source": [
        "download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JSyAVVe_uUJZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "\n",
        "# print(len(os.listdir('data')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0yqyyM7qvgF1"
      },
      "outputs": [],
      "source": [
        "def load_data(root, vfold_ratio=0.1, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S21Xzze2vmJ6"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "L88Pr8VMw74k",
        "outputId": "2043edbc-d0cb-4745-ef89-c7a12d873466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diving_board\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v_3O8RQjxA6p"
      },
      "outputs": [],
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6TLiXr-r0p",
        "outputId": "0a88668c-bf13-4984-f98c-47fe1ee131d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(450000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2O-1BvRbxD7D"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Convolution2D(128, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "\n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "# print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8g_V-8HxIZa",
        "outputId": "a81a659b-2104-411d-9621-5b2d9c87d47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1583/1583 - 38s - loss: 1.8117 - top_k_categorical_accuracy: 0.7997 - val_loss: 1.3207 - val_top_k_categorical_accuracy: 0.8843 - 38s/epoch - 24ms/step\n",
            "Epoch 2/15\n",
            "1583/1583 - 24s - loss: 1.1592 - top_k_categorical_accuracy: 0.9034 - val_loss: 1.0967 - val_top_k_categorical_accuracy: 0.9094 - 24s/epoch - 15ms/step\n",
            "Epoch 3/15\n",
            "1583/1583 - 23s - loss: 1.0091 - top_k_categorical_accuracy: 0.9191 - val_loss: 0.9957 - val_top_k_categorical_accuracy: 0.9202 - 23s/epoch - 15ms/step\n",
            "Epoch 4/15\n",
            "1583/1583 - 22s - loss: 0.9243 - top_k_categorical_accuracy: 0.9277 - val_loss: 0.9822 - val_top_k_categorical_accuracy: 0.9219 - 22s/epoch - 14ms/step\n",
            "Epoch 5/15\n",
            "1583/1583 - 22s - loss: 0.8710 - top_k_categorical_accuracy: 0.9326 - val_loss: 0.9135 - val_top_k_categorical_accuracy: 0.9277 - 22s/epoch - 14ms/step\n",
            "Epoch 6/15\n",
            "1583/1583 - 22s - loss: 0.8297 - top_k_categorical_accuracy: 0.9367 - val_loss: 0.8760 - val_top_k_categorical_accuracy: 0.9312 - 22s/epoch - 14ms/step\n",
            "Epoch 7/15\n",
            "1583/1583 - 25s - loss: 0.7959 - top_k_categorical_accuracy: 0.9396 - val_loss: 0.8633 - val_top_k_categorical_accuracy: 0.9325 - 25s/epoch - 16ms/step\n",
            "Epoch 8/15\n",
            "1583/1583 - 25s - loss: 0.7702 - top_k_categorical_accuracy: 0.9416 - val_loss: 0.8564 - val_top_k_categorical_accuracy: 0.9332 - 25s/epoch - 16ms/step\n",
            "Epoch 9/15\n",
            "1583/1583 - 25s - loss: 0.7492 - top_k_categorical_accuracy: 0.9442 - val_loss: 0.8288 - val_top_k_categorical_accuracy: 0.9345 - 25s/epoch - 16ms/step\n",
            "Epoch 10/15\n",
            "1583/1583 - 25s - loss: 0.7316 - top_k_categorical_accuracy: 0.9455 - val_loss: 0.8229 - val_top_k_categorical_accuracy: 0.9374 - 25s/epoch - 16ms/step\n",
            "Epoch 11/15\n",
            "1583/1583 - 26s - loss: 0.7162 - top_k_categorical_accuracy: 0.9469 - val_loss: 0.8327 - val_top_k_categorical_accuracy: 0.9355 - 26s/epoch - 16ms/step\n",
            "Epoch 12/15\n",
            "1583/1583 - 22s - loss: 0.7013 - top_k_categorical_accuracy: 0.9483 - val_loss: 0.8071 - val_top_k_categorical_accuracy: 0.9380 - 22s/epoch - 14ms/step\n",
            "Epoch 13/15\n",
            "1583/1583 - 22s - loss: 0.6893 - top_k_categorical_accuracy: 0.9495 - val_loss: 0.8231 - val_top_k_categorical_accuracy: 0.9353 - 22s/epoch - 14ms/step\n",
            "Epoch 14/15\n",
            "1583/1583 - 23s - loss: 0.6795 - top_k_categorical_accuracy: 0.9505 - val_loss: 0.8215 - val_top_k_categorical_accuracy: 0.9357 - 23s/epoch - 14ms/step\n",
            "Epoch 15/15\n",
            "1583/1583 - 21s - loss: 0.6683 - top_k_categorical_accuracy: 0.9511 - val_loss: 0.8178 - val_top_k_categorical_accuracy: 0.9357 - 21s/epoch - 14ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e5ab11e50>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf_uKblzxLmh",
        "outputId": "7414119d-36f5-4963-edff-5b11a71d5b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuarcy: 93.63%\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz99U9nfmxbC",
        "outputId": "e24c8225-8984-46ee-fde3-d01445faee2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://a6636dbc-2666-4521-b821-a4f6d60daf88/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://a6636dbc-2666-4521-b821-a4f6d60daf88/assets\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pickle.dump(model,open('model.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaheFWI80Fok",
        "outputId": "62e08991-e83c-44b3-b18e-5cfeea6f8d56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://c704f5c8-3a38-475a-bcdf-3949d744750c/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://c704f5c8-3a38-475a-bcdf-3949d744750c/assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "v7LK4Ee800l4",
        "outputId": "a4016806-3295-40be-92eb-fa319541c98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7e571312d0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "print(img.shape)\n",
        "plt.imshow(img.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LvkjxGEJ0_pp"
      },
      "outputs": [],
      "source": [
        "def predict(img):\n",
        "  pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "  ind = (-pred).argsort()[:5]\n",
        "  latex = [class_names[x] for x in ind]\n",
        "  print(latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbZyMlZHHwz7",
        "outputId": "411b5ec8-5745-4d9b-d737-8ec328fe34f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['smiley_face', 'face', 'moustache', 'beard', 'tooth']\n"
          ]
        }
      ],
      "source": [
        "predict(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy0gOiw_qoNM",
        "outputId": "8a7f5def-c656-41d4-bcd7-7381b0380b55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d5b7e7ce-09ed-4119-b3f6-660fdfa12f14/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d5b7e7ce-09ed-4119-b3f6-660fdfa12f14/assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nN2KwJ5s1DQZ"
      },
      "outputs": [],
      "source": [
        "list1=[]\n",
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        list1.append(item)\n",
        "        file_handler.write(\"{}\\n\".format(item))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvYOUpPhXlS1",
        "outputId": "779f3218-b790-40cc-bd9b-4ad4433633c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['line', 'candle', 'basketball', 'smiley_face', 'hammer', 'cat', 'shorts', 'screwdriver', 'grapes', 'frying_pan', 'mountain', 'eyeglasses', 'square', 'power_outlet', 'table', 'cell_phone', 'diving_board', 'spider', 'traffic_light', 'ice_cream', 'mushroom', 'flower', 'moustache', 'baseball_bat', 'snake', 'fan', 'ladder', 'alarm_clock', 'rainbow', 'cup', 'shovel', 'dumbbell', 'ceiling_fan', 'pants', 'hat', 'tooth', 'radio', 'cookie', 'lollipop', 'bridge', 'sword', 'bread', 't-shirt', 'car', 'pizza', 'lightning', 'bird', 'tent', 'scissors', 'sock', 'baseball', 'rifle', 'book', 'bed', 'bicycle', 'eye', 'door', 'tree', 'star', 'circle', 'cloud', 'microphone', 'saw', 'helmet', 'light_bulb', 'pencil', 'chair', 'headphones', 'airplane', 'clock', 'face', 'paper_clip', 'syringe', 'drums', 'broom', 'camera', 'umbrella', 'axe', 'beard', 'hot_dog', 'stop_sign', 'triangle', 'bench', 'tennis_racquet', 'sun', 'butterfly', 'coffee_cup', 'apple', 'donut', 'wristwatch', 'suitcase', 'knife', 'pillow', 'anvil', 'envelope', 'moon', 'wheel', 'laptop', 'key', 'spoon']\n"
          ]
        }
      ],
      "source": [
        "print(list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ENaxXMXlYr",
        "outputId": "61b677f5-e4f3-438b-c5a0-455495819113"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d42c64a0-4e8b-434e-a64e-9d374f0c8f3d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d42c64a0-4e8b-434e-a64e-9d374f0c8f3d/assets\n"
          ]
        }
      ],
      "source": [
        "np.save('model.npy',model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZE5PzqT1I9q"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmCfRzV41Pit",
        "outputId": "27f7b107-0cc8-479b-a1ed-dbe3b78eb851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['line', 'candle', 'basketball', 'smiley_face', 'hammer', 'cat', 'shorts', 'screwdriver', 'grapes', 'frying_pan', 'mountain', 'eyeglasses', 'square', 'power_outlet', 'table', 'cell_phone', 'diving_board', 'spider', 'traffic_light', 'ice_cream', 'mushroom', 'flower', 'moustache', 'baseball_bat', 'snake', 'fan', 'ladder', 'alarm_clock', 'rainbow', 'cup', 'shovel', 'dumbbell', 'ceiling_fan', 'pants', 'hat', 'tooth', 'radio', 'cookie', 'lollipop', 'bridge', 'sword', 'bread', 't-shirt', 'car', 'pizza', 'lightning', 'bird', 'tent', 'scissors', 'sock', 'baseball', 'rifle', 'book', 'bed', 'bicycle', 'eye', 'door', 'tree', 'star', 'circle', 'cloud', 'microphone', 'saw', 'helmet', 'light_bulb', 'pencil', 'chair', 'headphones', 'airplane', 'clock', 'face', 'paper_clip', 'syringe', 'drums', 'broom', 'camera', 'umbrella', 'axe', 'beard', 'hot_dog', 'stop_sign', 'triangle', 'bench', 'tennis_racquet', 'sun', 'butterfly', 'coffee_cup', 'apple', 'donut', 'wristwatch', 'suitcase', 'knife', 'pillow', 'anvil', 'envelope', 'moon', 'wheel', 'laptop', 'key', 'spoon']\n"
          ]
        }
      ],
      "source": [
        "print(list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n6MvDjvR8nVp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "cfTeKPir82yn",
        "outputId": "0df3fd43-af51-436b-9013-2f044fa02cca"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-131b2d95e224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/keras.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/keras.h5"
          ]
        }
      ],
      "source": [
        "model=load_model('/content/keras.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC6bEB-3uSdw",
        "outputId": "0d9e44fc-b49d-490e-e808-5d7b1b9d37ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://707eea19-8c94-4631-95dc-e14eb1bf9aeb/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://707eea19-8c94-4631-95dc-e14eb1bf9aeb/assets\n"
          ]
        }
      ],
      "source": [
        "pickle.dump(model,open('model.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RBzROUXM_aOo"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ER_7vbVD_aYe"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fF9C1ue8957"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "  \n",
        "image=Image.open('/content/candle - Copy.JPG')\n",
        "image=ImageOps.grayscale(image)\n",
        "image=resize(np.array(image),(28,28))\n",
        "image=np.array(image)\n",
        "im = np.where(image == 255, 0, image)\n",
        "im = np.where(im != 0, 255-im, im)\n",
        "x=image\n",
        "print(x.shape)\n",
        "plt.imshow(x.squeeze())\n",
        "x= x.reshape(image_size, image_size, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UICze1NW_fty"
      },
      "outputs": [],
      "source": [
        "x= x.reshape(1, image_size, image_size, 1).astype('float32')\n",
        "pred = model.predict(x)[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[i] for i in ind]\n",
        "print(latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRY7IWTRARkt"
      },
      "outputs": [],
      "source": [
        "shapes = ['hexagon','octagon','circle','line','lightning']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bm7hFmnATJF"
      },
      "outputs": [],
      "source": [
        "x=x_train[0]*255\n",
        "neededformat=x%255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqLaepNDFt2C"
      },
      "outputs": [],
      "source": [
        "neededformat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxRgOMtjGKQb"
      },
      "outputs": [],
      "source": [
        "def cropimage(im):\n",
        "  im=ImageOps.grayscale(im)\n",
        "  im=np.array(im)\n",
        "  im = np.where(im == 255, 0, im)\n",
        "  im = np.where(im != 0, 255-im, im)\n",
        "  # printarray2d(im)\n",
        "  imagedim=[]\n",
        "  start=[]\n",
        "  maxwidth=0\n",
        "  startrow=-1\n",
        "  endrow=-1\n",
        "  for i in range(im.shape[0]):\n",
        "    listrow=[]\n",
        "    for j in range(im.shape[1]):\n",
        "      if im[i][j]!=0:\n",
        "        listrow=im[i,j:].tolist()\n",
        "        start.append(j)\n",
        "        break\n",
        "    for k in range(len(listrow)-1,0,-1):\n",
        "      if listrow[k]!=0:\n",
        "        listrow=listrow[:k+1]\n",
        "        if len(listrow)!=0:\n",
        "          if start[-1]+len(listrow)>maxwidth:\n",
        "            maxwidth=start[-1]+len(listrow)\n",
        "          if len(imagedim)==0:\n",
        "            startrow=i\n",
        "          endrow=i\n",
        "          imagedim.append(listrow)\n",
        "        break\n",
        "  imgdimarr=np.array(imagedim)\n",
        "  min_start=np.min(start)\n",
        "  imgcrop=im[startrow-50:endrow+50,min_start-50:maxwidth+50]\n",
        "  return imgcrop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtjVRUSFf2JX"
      },
      "outputs": [],
      "source": [
        "def predictimage(im):\n",
        "  imgcrop=cropimage(im)\n",
        "  imgcropped=resize(imgcrop,(28,28))\n",
        "  x=imgcropped\n",
        "  x= x.reshape(image_size, image_size, 1).astype('float32')\n",
        "  x=x*3\n",
        "  pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "  ind = (-pred).argsort()[:5]\n",
        "  latex = [class_names[i] for i in ind]\n",
        "  print(latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMNXLk6YW6yG"
      },
      "outputs": [],
      "source": [
        "im=Image.open('/content/icecream.JPG')\n",
        "predictimage(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsqXnmlQJuAa"
      },
      "outputs": [],
      "source": [
        "def printarray2d(x):\n",
        "  for i in range(0,x.shape[0]):\n",
        "    for j in range(0,x.shape[1]):\n",
        "      print(np.round(x[1][j],3),end=\" \")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVFcvK3dAaEs"
      },
      "outputs": [],
      "source": [
        "def printarray(x):\n",
        "  for i in range(0,x.shape[0]):\n",
        "    for j in range(0,x.shape[1]):\n",
        "      print(np.round(x[i][j][0],3),end=\" \")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efMyDPV2HyoD"
      },
      "outputs": [],
      "source": [
        "printarray(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfhibZGGJx5I"
      },
      "outputs": [],
      "source": [
        "printarray(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJQH4_kjJ0FW"
      },
      "outputs": [],
      "source": [
        "predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEPCUdoSKrN3"
      },
      "outputs": [],
      "source": [
        "np.max(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rdzijkdMae9"
      },
      "outputs": [],
      "source": [
        "printarray(np.array(im))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htz1vmAbG29K"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from PIL import Image,ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1YkY58jQTbZ"
      },
      "outputs": [],
      "source": [
        "def inputpreprocessing():\n",
        "  img = \"/content/stopsign.JPG\"\n",
        "\n",
        "  img = Image.open(img)\n",
        "  # img=np.array(img)\n",
        "  if img.mode == \"CMYK\":\n",
        "      # color profiles can be found at C:\\Program Files (x86)\\Common Files\\Adobe\\Color\\Profiles\\Recommended\n",
        "      img = ImageCms.profileToProfile(img, \"USWebCoatedSWOP.icc\", \"sRGB_Color_Space_Profile.icm\", outputMode=\"RGB\")\n",
        "  # PIL image -> OpenCV image; see https://stackoverflow.com/q/14134892/2202732\n",
        "  img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  ## (1) Convert to gray, and threshold\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "  ## (2) Morph-op to remove noise\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
        "  morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  ## (3) Find the max-area contour\n",
        "  cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "  cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
        "\n",
        "  ## (4) Crop and save it\n",
        "  x,y,w,h = cv2.boundingRect(cnt)\n",
        "  dst = img[y:y+h, x:x+w]\n",
        "\n",
        "  # add border/padding around the cropped image\n",
        "  # dst = cv2.copyMakeBorder(dst, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=[255,255,255])\n",
        "\n",
        "  # cv2.imshow(\"image\", dst)\n",
        "  # plt.imshow(dst)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "  # create/write to file\n",
        "  # cv2.imwrite(\"001.png\", dst)\n",
        "  WHITE = [255,255,255]\n",
        "  im= cv2.copyMakeBorder(dst.copy(),50,50,50,50,cv2.BORDER_CONSTANT,value=WHITE)\n",
        "  img=np.array(im)\n",
        "  img = np.where(img == 255, 0, img)\n",
        "  im = np.where(img != 0, 255-img, img)\n",
        "  # im=Image.fromarray(img)\n",
        "  im=Image.fromarray(im)\n",
        "  im=ImageOps.grayscale(im)\n",
        "  im=np.array(im)\n",
        "  im=resize(im,(28,28))\n",
        "  # plt.imshow(im)\n",
        "  x=im\n",
        "  image_size=28\n",
        "  x.shape\n",
        "  x = x.reshape(image_size, image_size, 1).astype('float32')\n",
        "  x = x*3\n",
        "  # print(x)\n",
        "  pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "  ind = (-pred).argsort()[:5]\n",
        "  latex = [gamecat[i] for i in ind]\n",
        "  print(latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaQxXCaXU7uP"
      },
      "outputs": [],
      "source": [
        "inputpreprocessing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG9OBrYjI2rt"
      },
      "outputs": [],
      "source": [
        "WHITE = [255,255,255]\n",
        "constant= cv2.copyMakeBorder(dst.copy(),50,50,50,50,cv2.BORDER_CONSTANT,value=BLUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp9MRSaOI21Z"
      },
      "outputs": [],
      "source": [
        "img=numpy.array(constant)\n",
        "img = np.where(img == 255, 0, img)\n",
        "im = np.where(img != 0, 255-img, img)\n",
        "# im=Image.fromarray(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT1hQEy1SNBq"
      },
      "outputs": [],
      "source": [
        "im=Image.fromarray(im)\n",
        "im=ImageOps.grayscale(im)\n",
        "im=np.array(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYf6MMdbG1dS"
      },
      "outputs": [],
      "source": [
        "im=resize(im,(28,28))\n",
        "plt.imshow(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J95t89b5IY32"
      },
      "outputs": [],
      "source": [
        "x=im\n",
        "image_size=28\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrdULUdSInH7"
      },
      "outputs": [],
      "source": [
        "x = x.reshape(image_size, image_size, 1).astype('float32')\n",
        "x = x*3\n",
        "print(x)\n",
        "pred = model.predict(numpy.expand_dims(x, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [gamecat[i] for i in ind]\n",
        "print(latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J-BA5NuJ3Bs"
      },
      "outputs": [],
      "source": [
        "gamecat = ['spider', 'bed', 'sock', 'frying_pan', 'grapes', 'basketball', 'axe', 'wristwatch', 'bread', 'anvil',\n",
        "           'mountain', 'rifle', 'rainbow', 'stop_sign', 'power_outlet', 'alarm_clock',\n",
        "           'drums', 'lollipop', 'cookie', 'knife', 'scissors', 'flower', 'pencil', 'apple', 'car', 'tent', 'cat', 'beard',\n",
        "           'umbrella', 'butterfly', 'radio', 'shovel', 'sun', 'syringe', 'bird', 'sword', 'book', 'face', 'baseball', 'laptop', 'hammer',\n",
        "           'ice_cream', 'spoon', 'tree', 'microphone', 'bridge', 'traffic_light', 'star', 'diving_board', 'shorts',\n",
        "           'chair', 'eyeglasses', 'fan', 'tooth', 'cell_phone', 'headphones', 'saw', 'pillow', 'cup', 'square', 'circle',\n",
        "           'light_bulb', 'paper_clip', 'screwdriver', 'tennis_racquet', 'coffee_cup', 'envelope', 'hat', 'hot_dog', 'ceiling_fan',\n",
        "           'suitcase', 'bench', 'moon', 'wheel', 'cloud', 'eye', 'line', 'pants', 'airplane', 'smiley_face', 'camera', 'moustache',\n",
        "           'pizza', 'triangle', 'broom', 'key', 'bicycle', 'snake', 'donut', 'clock', 'dumbbell', 'candle', 'ladder', 't-shirt', 'mushroom',\n",
        "           'helmet', 'baseball_bat', 'lightning', 'table', 'door']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsUa1tfCKkh9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DoodleDraw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
